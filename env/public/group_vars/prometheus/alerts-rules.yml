---
prometheus_alert_rules:
  - alert: Watchdog
    expr: vector(1)
    for: 10m
    labels:
      severity: info
    annotations:
      description: 'This is an alert meant to ensure that the entire alerting pipeline is functional. '
      summary: 'Ensure entire alerting pipeline is functional'
  - alert: InstanceDown
    expr: 'up == 0'
    for: 5m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} down{% endraw %}"
  - alert: CriticalCPULoad 95
    expr: '100 - (avg by (instance) (irate(node_cpu_seconds_total{job=~"node.*.exporter",mode="idle",instance!~"app1.example.com:9100"}[10m])) * 100) > 96'
    for: 2m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has Critical CPU load for more than 10 minutes.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} - Critical CPU load{% endraw %}"
  - alert: CriticalRAMUsage - 10
    expr: '(1 - ((node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) / node_memory_MemTotal_bytes)) * 100 > 90'
    for: 5m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} has Critical Memory Usage more than 5 minutes.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} has Critical Memory Usage over 90%{% endraw %}"
  - alert: VeryCriticalRAMUsage
    expr: '(1 - ((node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) / node_memory_MemTotal_bytes)) * 100 > 90'
    for: 5m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} has Very Critical Memory Usage more than 5 minutes.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} has Critical Memory Usage{% endraw %}"
#  - alert: CriticalDiskSpace lower 30
#    expr: 'node_filesystem_free_bytes{mountpoint!~"^/run(/.*|$)",fstype!~"(squashfs|fuse.*)",job=~"node.*.exporter"} / node_filesystem_size_bytes{job=~"node.*.exporter"} < 0.3'
#    for: 5m
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has less than 30% space remaining.{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - Critical disk space usage{% endraw %}"
#  - alert: CriticalDiskSpace lower 20
#    expr: 'node_filesystem_free_bytes{mountpoint!~"^/run(/.*|$)",fstype!~"(squashfs|fuse.*)",job=~"node.*.exporter"} / node_filesystem_size_bytes{job=~"node.*.exporter"} < 0.2'
#    for: 15m
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has less than 20% space remaining.{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - Critical disk space usage{% endraw %}"
#  - alert: CriticalDiskSpace lower 15
#    expr: 'node_filesystem_free_bytes{mountpoint!~"^/run(/.*|$)",fstype!~"(squashfs|fuse.*)",job=~"node.*.exporter"} / node_filesystem_size_bytes{job=~"node.*.exporter"} < 0.15'
#    for: 4m
#    labels:
#      severity: critical
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has less than 10% space remaining.{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - Critical disk space usage{% endraw %}"
  - alert: CriticalDiskSpace lower 10
    expr: 'node_filesystem_free_bytes{mountpoint!~"^/run(/.*|$)",fstype!~"(squashfs|fuse.*)",job=~"node.*.exporter"} / node_filesystem_size_bytes{job=~"node.*.exporter"} < 0.1'
    for: 4m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has less than 10% space remaining.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} - Critical disk space usage{% endraw %}"
  - alert: CriticalDiskSpace lower 5
    expr: 'node_filesystem_free_bytes{mountpoint!~"^/run(/.*|$)",fstype!~"(squashfs|fuse.*)",job=~"node.*.exporter"} / node_filesystem_size_bytes{job=~"node.*.exporter"} < 0.05'
    for: 4m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has less than 5% space remaining.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} - Critical disk space usage{% endraw %}"
# need set cron job and hands metrics
#  - alert: RebootRequired
#    expr: "node_reboot_required > 0"
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} requires a reboot.{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - reboot required{% endraw %}"
  - alert: SslCertificateWillExpireSoon
    expr: 'probe_ssl_earliest_cert_expiry - time() < 86400 * 7'
    for: 2m
    labels:
      severity: warning
    annotations:
     description: "{% raw %}SSL certificate expires in 7 days\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
     summary: "{% raw %}SSL certificate will expire soon (instance {{ $labels.instance }}){% endraw %}"
  - alert: Domain_expire
    expr: 'domain_expiry_days{job="domain_expire", domain!="example.net"} < 30'
    for: 0m
    labels:
      severity: warning
    annotations:
     description: "{% raw %}Domain expire 30 days\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
     summary: "{% raw %}Domain expire will expire soon (domain {{ $labels.domain }}){% endraw %}"
  - alert: Domain_probe_fail
    expr: 'domain_probe_success !=1'
    for: 0m
    labels:
      severity: warning
    annotations:
     description: "{% raw %}Domain expire probe fail\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
     summary: "{% raw %}Domain expire probe fail (domain {{ $labels.domain }}){% endraw %}"
#  - alert: ShardCountES c2-infra
#    expr: 'elasticsearch_cluster_health_active_shards{instance="es-01.example.com:9114"} > 1500'
#    for: 2m
#    labels:
#      severity: warning
#    annotations:
#     description: "{% raw %}Elasticsearch active shard moor 950\n VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
#     summary: "{% raw %}lasticsearch active shard moor 750 (instance {{ $labels.instance }}){% endraw %}"
  - alert: IpsecStatus
    expr: 'ipsec_status > 0'
    for: 2m
    labels:
      severity: warning
    annotations:
     description: "{% raw %}IPsec tunnel status not 0\n VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
     summary: "{% raw %}check work (instance {{ $labels.instance }}){% endraw %}"
#  - alert: MySqlSlaveStatus
#    expr: '(mysql_slave_status_slave_io_running + mysql_slave_status_slave_sql_running) < 2'
#    for: 2m
#    labels:
#      severity: critical
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} Slave not runnig for more than 2 minutes.{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - Slave down{% endraw %}"
#  - alert: MySqlBehindMaster
#    expr: 'mysql_slave_status_seconds_behind_master > 200'
#    for: 2m
#    labels:
#      severity: critical
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} Slave behind master more.{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - Slave behind {{ humanize $value }}{% endraw %}"
#  - alert: MySqlSlaveError
#    expr: 'mysql_slave_status_last_sql_errno != 0'
#    for: 2m
#    labels:
#      severity: critical
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} Slave replication error.{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - Error slave replication {{ humanize $value }}{% endraw %}"
#  - alert: MySqlUserConnection
#    expr: 'mysql_info_schema_processes_by_user{stand="c1-infra"}  > 80'
#    for: 2m
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} To many user connection{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - To many active user {{ $labels.mysql_user }} connection - {{ humanize $value }}{% endraw %}"
#  - alert: MySqlProcessState
#    expr: 'sum(mysql_info_schema_threads{instance="mysql-18.example.com:9104"}) > 300'
#    for: 2m
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}mysql-18.example.com to active process moore 220{% endraw %}"
#      summary: "{% raw %}mysql-18.example.com - To many active process state - {{ humanize $value }}{% endraw %}"
#  - alert:  MySql Critical prepared stmt
#    expr: 'mysql_global_status_prepared_stmt_count > 10000'
#    for: 2m
#    labels:
#      severity: critical
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} prepared stmt more 10000.{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - prepared stmt {{ humanize $value }}{% endraw %}"
  - alert: HTTP-200-Fail
#    expr: (probe_http_status_code{instance=~"{{ http_200_fail | join('|') }}" })!=200
    expr: probe_http_status_code{job="blackbox", instance!~"({{ http_200_fail | join('|') }})"} != 200
    for: 1m
    labels:
      severity: warning
    annotations:
      description: "{% raw %}{{ $labels.instance }} response code not eq 200{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} - response code not eq - {{ humanize $value }}.\nHTTP_CODE = {{ printf \"%.2f\" $value }}{% endraw %}"
#  - alert: Clickhouse critical rows in table rates
#    expr: 'clickhouse_table_parts_rows{table="aggregated_rates",stand="c1-infra"} > 2002423912'
#    for: 1m
#    labels:
#      severity: critical
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} Rows to table aggregated_rates to more 2002423912{% endraw %}"
#      summary: "{% raw %}Critical {{ $labels.instance }} - Rows to table aggregated_rates to more  - {{ humanize $value }}{% endraw %}"
  - alert: clickhouse to many connections
    expr: 'clickhouse_tcp_connection > 10 or clickhouse_http_connection > 10 or clickhouse_interserver_connection > 10'
    for: 3m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} to many connection{% endraw %}"
      summary: "{% raw %}Critical {{ $labels.instance }} - to many connection {{ humanize $value }}{% endraw %}"
#  - alert: Clickhouse tables rates less
#    expr: 'clickhouse_table_parts_rows{table="aggregated_rates",stand="c1-infra"} < 27000000'
#    for: 1m
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} Rows to table aggregated_rates to less 27000000{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - Rows to table aggregated_rates to less - {{ humanize $value }}{% endraw %}"
#  - alert: clickhouse rates to many connections
#    expr: 'clickhouse_http_connection{table="aggregated_rates",stand="c1-infra"} > 200'
#    for: 1m
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} To manny connection for ch prod{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - To many connection clickhouse - {{ humanize $value }}{% endraw %}"
#  - alert: NomadJobFailed
#    expr: 'delta(nomad_nomad_job_summary_failed[1m])> 0'
#    for: 0m
#    labels:
#      severity: warning
#    annotations:
#      summary: "{% raw %}Nomad job {{ $labels.exported_job }} failed to {{ $labels.instance }}{% endraw %}"
#      description: "{% raw %}Nomad job failed {{ $labels.exported_job }} to {{ $labels.instance }}{% endraw %}"
#  - alert: NomadJobLost
#    expr: 'nomad_nomad_job_summary_lost > 0'
#    for: 0m
#    labels:
#      severity: warning
#    annotations:
#      summary: "{% raw %}Nomad job lost (instance {{ $labels.instance }}){% endraw %}"
#      description: "{% raw %}Nomad job lost\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}{% endraw %}"
#  - alert: NomadJobRestart
#    expr: 'nomad_client_allocs_restart > 0'
#    for: 0m
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.exported_job }} nomad job restart{% endraw %}"
#      summary: "{% raw %} Job {{ $labels.exported_job }} restarted to {{ $labels.instance }}{% endraw %}"
#  - alert: NomadBlockedEvaluation
#    expr: 'nomad_nomad_blocked_evals_total_blocked > 0'
#    for: 0m
#    labels:
#      severity: warning
#    annotations:
#      summary: "{% raw %}Nomad blocked evaluation (instance {{ $labels.instance }}){% endraw %}"
#      description: "{% raw %}Nomad blocked evaluation\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}{% endraw %}"
#  - alert: NomadJobQueued
#    expr: 'nomad_nomad_job_summary_queued > 0'
#    for: 2m
#    labels:
#      severity: warning
#    annotations:
#      summary: "{% raw %}Nomad job queued (instance {{ $labels.instance }}){% endraw %}"
#      description: "{% raw %}Nomad job queued\n  {{ $labels.exported_job }}  {{ $labels.instance }}{% endraw %}"
  - alert: Consul_service_status
    expr: 'consul_catalog_service_node_healthy{node!~"daemons-.*."} == 0'
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Catalog service consul healthckeck failed{% endraw %}"
      description: "{% raw %}Service: {{ $labels.service_name }} to {{ $labels.node }}{% endraw %}"
  - alert: Consul_missing_master_node
    expr: 'consul_raft_peers < 5'
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "{% raw %}Numbers of consul raft peers should be 5, in order to preserve quorum{% endraw %}"
      description: "{% raw %}Consul raft peers {{ $value }} - {{ $labels.instance }}{% endraw %}"
  - alert: Consul_agent_inhealthy
    expr: 'consul_health_node_status{status="critical"} == 1'
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "{% raw %}Consul agent unhealthy{% endraw %}"
      description: "{% raw %}Consul agent unhealthy - {{ $labels.instance }}{% endraw %}"
#  - alert: Nats too many connections to server
#    expr: "gnatsd_connz_num_connections > 120"
#    for: '1m'
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} too many connections to NATS{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - too many connections to NATS ({{ humanize $value}}){% endraw %}"
#  - alert: Nats too many subscriptions to server
#    expr: "gnatsd_varz_subscriptions > 320"
#    for: '1m'
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} too many subscriptions to NATS{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - too many subscriptions to NATS ({{ humanize $value}}){% endraw %}"
#  - alert: Nats too many consumers to server
#    expr: "gnatsd_varz_slow_consumers > 3"
#    for: '1m'
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} too many consumers to NATS{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - too many consumers to NATS ({{ humanize $value}}){% endraw %}"
#  - alert: Critical redis db keys
#    expr: 'redis_db_keys > 1000000'
#    for: '1m'
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}{{ $labels.instance }} redis db keys alert to more 1000000 {% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - redis db keys alert to more ({{ humanize $value}}){% endraw %}"
  - alert: Critical node time seconds
    expr: 'abs(time() - node_time_seconds) > 60'
    for: '1m'
    labels:
      severity: warning
    annotations:
      description: "{% raw %}{{ $labels.instance }} node time seconds alert to more 60 {% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} - node time seconds alert to more ({{ humanize $value}}){% endraw %}"
  - alert: Vault instance sealed
    expr: 'vault_core_unsealed == 0'
    for: '0m'
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} Vault instance sealed {% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} - Vault instance sealed ({{ humanize $value}}){% endraw %}"
  - alert: ClockSkewDetected new
#    expr: 'abs(node_timex_offset_seconds) * 1000 > 5'
    expr: 'abs(node_timex_estimated_error_seconds) * 1000 > 5'
    for: 2m
    labels:
      severity: warning
    annotations:
      description: "{% raw %}Clock skew detected on {{ $labels.instance }}. Ensure NTP is configured correctly on this host.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} - Clock skew detected{% endraw %}"
# new rules
# https://monitoring.mixins.dev/node-exporter/
  - alert: NodeFilesystemAlmostOutOfSpace
    annotations:
      description: "{% raw %}Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint}}, at {{ $labels.instance }} has only  available space left{% endraw %}"
      summary: "Filesystem has less than 5% space left"
    expr: '(node_filesystem_avail_bytes{job="node-exporter",fstype!="",mountpoint!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!="",mountpoint!=""} * 100 < 5 and node_filesystem_readonly{job="node-exporter",fstype!="",mountpoint!=""} == 0 )'
    for: 30m
    labels:
      severity: warning
  - alert: NodeClockSkewDetected - 0.05
    annotations:
      summary: "{% raw %}Clock skew detected (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Clock at {{ $labels.instance }} is out of sync by more than 0.05s. Ensure NTP is configured correctly on this host. VALUE = {{ printf \"%.8f\" $value }}s{% endraw %}"
    expr: ((node_timex_offset_seconds > 0.05 and deriv(node_timex_offset_seconds[5m]) >= 0) or (node_timex_offset_seconds < -0.05 and deriv(node_timex_offset_seconds[5m]) <= 0)) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    for: 10m
    labels:
      severity: warning
  - alert: NodeClockNotSynchronising
    annotations:
      description: "{% raw %}Clock at {{ $labels.instance }} is not synchronising. Ensure NTP is configured on this host.{% endraw %}"
      summary: Clock not synchronising.
    expr: |
      min_over_time(node_timex_sync_status{job="node-exporter"}[5m]) == 0
      and
      node_timex_maxerror_seconds{job="node-exporter"} >= 16
    for: 10m
    labels:
      severity: warning
  - alert: NodeCPUHighUsage - 90
    annotations:
      description: "{% raw %}CPU usage at {{ $labels.instance }} has been above 90%, VALUE = {{ printf \"%.2f\" $value }} for the last 15 minutes, is currently at  {% endraw %}"
      summary: High CPU usage.
    expr: |
      sum without(mode) (avg without (cpu) (rate(node_cpu_seconds_total{job="node-exporter", mode!="idle"}[15m]))) * 100 > 90
    for: 15m
    labels:
      severity: info
  - alert: NodeCPUHighUsage - 80
    annotations:
      description: "{% raw %}CPU usage at {{ $labels.instance }} has been above 80%, VALUE = {{ printf \"%.2f\" $value }}for the last 15 minutes, is currently at  {% endraw %}"
      summary: High CPU usage.
    expr: |
      sum without(mode) (avg without (cpu) (rate(node_cpu_seconds_total{job="node-exporter", mode!="idle",instance!~"app5.example.com:9100"}[15m]))) * 100 > 80
    for: 15m
    labels:
      severity: info
  - alert: NodeCPUHighUsage - 70
    annotations:
      description: "{% raw %}CPU usage at {{ $labels.instance }} has been above 70%, VALUE = {{ printf \"%.2f\" $value }}for the last 15 minutes, is currently at  {% endraw %}"
      summary: High CPU usage.
    expr: |
      sum without(mode) (avg without (cpu) (rate(node_cpu_seconds_total{job="node-exporter", mode!="idle",instance!~"app1.example.com:9100"}[15m]))) * 100 > 70
    for: 15m
    labels:
      severity: info
  - alert: NodeMemoryHighUtilization
    annotations:
      description: "{% raw %}Memory is filling up at {{ $labels.instance }}, has been above 90% for the last 15 minutes, is currently at {% endraw %}"
      summary: Host is running out of memory.
    expr: |
      100 - (node_memory_MemAvailable_bytes{job="node-exporter"} / node_memory_MemTotal_bytes{job="node-exporter"} * 100) > 90
    for: 15m
    labels:
      severity: warning
  - alert: NodeDiskIOSaturation
    annotations:
      description: "{% raw %}Disk IO queue (aqu-sq) is high on {{ $labels.device }} at {{ $labels.instance }}, has been above 10 for the last 15 minutes, is currently at. This symptom might indicate disk saturation.{% endraw %}"
      summary: Disk IO queue is high.
    expr: |
      rate(node_disk_io_time_weighted_seconds_total{job="node-exporter", device!=""}[5m]) > 10
    for: 30m
    labels:
      severity: warning
#### https://samber.github.io/awesome-prometheus-alerts/rules#host-and-hardware
  # Please add ignored mountpoints in node_exporter parameters like
  # "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/)".
  # Same rule using "node_filesystem_free_bytes" will fire when disk fills for non-root users.
  - alert: HostOutOfDiskSpace - 10
    expr: '(((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10) and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}'
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Host out of disk space (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Disk is almost full (< 10% left)\n  VALUE = {{ printf \"%.2f\" $value }}\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: HostOutOfDiskSpace - 20
#    expr: '(((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 20) and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}'
#    expr: '(((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 20) and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{instance!~"app3.example.com:9100"}'
    expr: |
      (((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 20) 
      and ON (instance, device, mountpoint) node_filesystem_readonly == 0)
      * on(instance) group_left (nodename) node_uname_info{instance!~"{{ excl_inst_out_of_disk_space_20 | join('|') }}"}
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Host out of disk space (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Disk is almost full (< 20% left)\n  VALUE = {{ printf \"%.2f\" $value }}\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: HostOutOfDiskSpace - 30
#    expr: '(((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 30) and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}'
#    expr: '(((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 30) and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{nodename!~"app3.example.com:9100"}'
    expr: >
      (((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 30) and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{instance!~"{{ excluded_instances_host_disk_out_30 | join('|') }}"}
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Host out of disk space (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Disk is almost full (< 30% left)\n  VALUE = {{ printf \"%.2f\" $value }}\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: HostDiskWillFillIn24Hours
    expr: '(((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10) and ON (instance, device, mountpoint) predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}'
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Host disk will fill in 24 hours (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Filesystem is predicted to run out of space within the next 24 hours at current write rate\n  VALUE = {{ printf \"%.2f\" $value }}\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: HostOutOfInodes - 10
    expr: '((node_filesystem_files_free / node_filesystem_files * 100 < 10) and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}'
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Host out of inodes (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Disk is almost running out of available inodes (< 10% left)\n  VALUE = {{ printf \"%.2f\" $value }}\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: HostOutOfInodes - 20
    expr: '((node_filesystem_files_free / node_filesystem_files * 100 < 20) and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}'
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Host out of inodes (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Disk is almost running out of available inodes (< 20% left)\n  VALUE = {{ printf \"%.2f\" $value }}\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: HostOutOfInodes - 30
    expr: '((node_filesystem_files_free / node_filesystem_files * 100 < 30) and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}'
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Host out of inodes (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Disk is almost running out of available inodes (< 30% left)\n  VALUE = {{ printf \"%.2f\" $value }}\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: HighDiskIOPS - 10m over 500 iops
#    expr: rate(node_disk_reads_completed_total{instance!~"app3.example.com:9100"}[10m]) + rate(node_disk_writes_completed_total[5m]) > 100
    expr: >
      rate(node_disk_reads_completed_total{instance!~"{{ excluded_instances_hight_disk_iops_15m | join('|') }}"}[15m]) +
      rate(node_disk_writes_completed_total[15m]) > 500
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}High Disk IOPS on instance {{ $labels.instance }}{% endraw %}"
      description: "{% raw %}Disk IOPS on instance {{ $labels.instance }} has exceeded 100 IOPS over the last 10 minutes.\nCurrent IOPS: {{ printf \"%.2f\" $value }}{% endraw %}"
  - alert: HighDiskIOPS - 1h over 500 iops
    expr: >
      rate(node_disk_reads_completed_total{instance!~"{{ excluded_instances_hight_disk_iops_1h | join('|') }}"}[1h]) + 
      rate(node_disk_writes_completed_total[1h]) > 500
    for: 1h
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}High Disk IOPS on instance {{ $labels.instance }}{% endraw %}"
      description: "{% raw %}Disk IOPS on instance {{ $labels.instance }} has exceeded 100 IOPS over the last 1 hour.\nCurrent IOPS: {{ printf \"%.2f\" $value }}{% endraw %}"
  - alert: HostUnusualNetworkThroughputIn - 10m
    expr: (sum by (instance) (rate(node_network_receive_bytes_total{instance!~"app3.example.com:9100"}[5m])) / 1024 / 1024 > 10) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Host unusual network throughput in (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Host network interfaces are probably receiving too much data (> 10 MB/s)\n  VALUE = {{ printf \"%.2f\" $value }} MB/s\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: HostUnusualNetworkThroughputOut - 5m
#    expr: (sum by (instance) (rate(node_network_transmit_bytes_total[5m])) / 1024 / 1024 > 10) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    expr: (sum by (instance) (rate(node_network_transmit_bytes_total{instance!~"app1.example.com:9100"}[5m])) / 1024 / 1024 > 10) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Host unusual network throughput out (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Host network interfaces are probably sending too much data (> 10 MB/s)\n  VALUE = {{ printf \"%.2f\" $value }} MB/s\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: HostOutOfMemory - 10
    expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Host out of memory (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Node memory is filling up (< 10% left)\n  VALUE = {{ printf \"%.2f\" $value }}\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: HostOutOfMemory - 20
#    expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 20) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 20) * on(instance) group_left (nodename) node_uname_info{instance!~"app2.example.com:9100"}
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Host out of memory (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Node memory is filling up (< 20% left)\n  VALUE = {{ printf \"%.2f\" $value }}\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: HostOutOfMemory - 30
#    expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 30) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 30) * on(instance) group_left (nodename) node_uname_info{instance!~"app2.example.com:9100"}
    for: 30m
    labels:
      severity: info
    annotations:
      summary: "{% raw %}Host out of memory (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Node memory is filling up (< 30% left)\n  VALUE = {{ printf \"%.2f\" $value }}\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: LotClickHouseTCPConnection - 50
    annotations:
      description: "{% raw %}TCP connections at {{ $labels.instance }} have been above 50 for the last 10 minutes, current value is {{ printf \"%.2f\" $value }}{% endraw %}"
      summary: "High TCP connections in ClickHouse"
    expr: sum by (instance) (ClickHouseMetrics_TCPConnection) > 50
    for: 10m
    labels:
      severity: warning
  - alert: LotClickHouseHTTPConnection - 50
    annotations:
      description: "{% raw %}HTTP connections at {{ $labels.instance }} have been above 50 for the last 10 minutes, current value is {{ printf \"%.2f\" $value }}{% endraw %}"
      summary: High HTTP connections in ClickHouse.
    expr: sum by (instance) (ClickHouseMetrics_HTTPConnection) > 50
    for: 10m
    labels:
      severity: warning
  - alert: Remote host unavailability
    annotations:
      description: "{% raw %} Ping to {{ $labels.instance }} unavailability {{ printf \"%.2f\" $value }}{% endraw %}"
      summary: Remote host unavailability - ping metrics
    expr: |
      c1_euc1_c1_devops_load_250_ping_ms_amazon_com == 99999 or
      c1_euw2_c1_prod_lrm_420_ping_ms_egw_binance_ci_prod_com == 99999 or
      c1_euw2_c1_prod_lrm_420_ping_ms_apne1_c1_prod_mgmt_50_ci_prod_com == 99999 or
      c1_apne1_c1_prod_mgmt_50_ping_ms_lrm_420_ci_prod_com == 99999 or
      c1_apne1_c1_prod_mgmt_50_ping_ms_euw2_c1_prod_lrates_426_ci_prod_com == 99999
    for: 1m
    labels:
      severity: warning
  - alert: Remote host very high ping 165ms
    annotations:
      description: "{% raw %} Ping to {{ $labels.instance }} high {{ printf \"%.2f\" $value }}{% endraw %}"
      summary: Remote host very high ping  - ping metrics VPN channel
    expr: |
      c1_euc1_c1_devops_load_250_ping_ms_amazon_com > 165 or
      c1_euw2_c1_prod_lrm_420_ping_ms_egw_binance_ci_prod_com > 165 or
      c1_apne1_c1_prod_mgmt_50_ping_ms_lrm_420_ci_prod_com > 165
    for: 1m
    labels:
      severity: warning
  - alert: Remote host  very high ping 250
    annotations:
      description: "{% raw %} Ping to {{ $labels.instance }} high {{ printf \"%.2f\" $value }}{% endraw %}"
      summary: Remote host very high ping  - ping metrics internet
    expr: |
      c1_euw2_c1_prod_lrm_420_ping_ms_apne1_c1_prod_mgmt_50_ci_prod_com > 250 or
      c1_apne1_c1_prod_mgmt_50_ping_ms_euw2_c1_prod_lrates_426_ci_prod_com > 250
    for: 1m
    labels:
      severity: warning
  - alert: Textfile scrape error
    annotations:
      description: "{% raw %} Textfile scrape error on {{ $labels.instance }} {% endraw %}"
      summary: Textfile scrape error
    expr: |
      node_textfile_scrape_error == 1
    for: 1m
    labels:
      severity: warning
  - alert: HostMemoryUsageHigh 95%
    expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 5)
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "{% raw %}High memory usage detected on host (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Node memory usage has exceeded 95%\n  VALUE = {{ printf \"%.2f\" $value }}%\n  LABELS = {{ $labels }}{% endraw %}"
  - alert: HighOpenFileDescriptors over 50k
    expr: (node_filefd_allocated{instance!~"app2.example.com:9100"} > 50000)
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}High number of open file descriptors (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Node exporter has more than 50000 open file descriptors for more than 5 minutes.\n  VALUE = {{ printf \"%.2f\" $value }}%\n  LABELS = {{ $labels }}{% endraw %}"
